---
title: "R Notebook"
output: html_notebook
---

```{r}
library(rpart)
library(rpart.plot)
library(tidyverse)

library(tidyverse)
titanic_set <- read_csv('data/titanic_decision_tree_data.csv')

shuffle_index <- sample(1:nrow(titanic_set))

# shuffle the data so class order isn't in order - need this for training/testing split later on 
titanic_set <- titanic_set[shuffle_index, ]
```

```{r}
titanic_set
```

1.1 Question 1

Cleaning up the data is always the first step. Do the following:

Take only observations which have a survived flag (i.e. that aren’t missing)
Turn your important variables into factors (sex, survived, pclass, embarkation)
Create an age_status variable which groups individuals under (and including) 16 years of age into a category called “child” category and those over 16 into a category called “adult”.
Drop the NA
Drop any variables you don’t need (X1, passenger_id, name, ticket, far, cabin)
If you need help doing this, the code is below, but please try it yourself first so you can learn!

```{r}
titanic_tidy_set <- titanic_set %>% 
  filter(survived == 1 | survived == 0) %>% 
  mutate_if(is.character, as.factor) %>% 
  mutate(age_status = ifelse(age <= 16, "child", "adult")) %>% 
  drop_na() %>% 
  select(-c("X1","passenger_id", "name", "ticket", "fare", "cabin"))
              
titanic_tidy_set           
```


1.3 Question 3

Now you can start to build your model. Create your testing and training set using an appropriate split. Check you have balanced sets. Write down why you chose the split you did and produce output tables to show whether or not it is balanced. [Extra - if you want to force balanced testing and training sets, have a look at the stratified() function in package splitstackshape (you can specify multiple variables to stratify on by passing a vector of variable names to the group argument, and get back testing and training sets with argument bothSets = TRUE)]


```{r}
n_data <- nrow(titanic_tidy_set)

test_index <- sample(1:n_data, size = n_data * 0.2)

titanic_test <- slice(titanic_tidy_set, test_index)

titanic_train <- slice(titanic_tidy_set, -test_index)
```

```{r}
titanic_test

titanic_train
```
We have divided the dataset into 80-20 train and test dataset. The 20% of the existing dataset is new and it will help if testing the model for its accuracy, specificity and sensitivity.


1.4 Question 4

Create your decision tree to try and predict survival probability using an appropriate method, and create a decision tree plot.


```{r}
titanic_test %>% 
  janitor::tabyl(survived)
```

```{r}
titanic_train %>% 
  janitor::tabyl(survived)
```


```{r}
titanic_fit <- rpart(
  formula = survived ~ ., 
  data = titanic_train, 
  method = 'class'
)

rpart.plot(titanic_fit, 
           yesno = 2, 
           fallen.leaves = TRUE, 
           faclen = 5, 
           digits = 4)
```

1.5 Question 5

Write down what this tells you, in detail. What variables are important? What does each node tell you? Who has the highest chance of surviving? Who has the lowest? Provide as much detail as you can.

Using the train data, we plotted the decision tree. The top node shows that 0.68

The variables "age" and "sex" are picked by the decision tree because it is most informative in predicting whether a passenger on the titanic will survive.

Next, each node has three pieces of information:

1) The predicted result for a datapoint at the node (Survived) is on the top line.

2) The second line contains probability of a survival result expressed as a decimal. So for example, if the person was a male, then they had a 0.42 chance of not surviving. If the person was a female, they have a 0.94 chance of surviving. 

3)If the person was a male and age between 47.5 and 53, they would have had 0.62 chances of surviving.

4)If the person was a male and less than or equal to 36.25 age then they would have 0.62 chances of surviving.

The colouring of the nodes relates to this value, with dark blue nodes representing low probability and dark green high probability.

The percentage of datapoints which pass through this node. This will always be 100% at the root and the leaf nodes should always total 100%. The percentage on a given node should always be the sum of the percentages on its children.


1.6 Question 6


Test and add your predictions to your data. Create a confusion matrix. Write down in detail what this tells you for this specific dataset.


```{r}
library(modelr)

titanic_test_pred <- titanic_test %>% 
  add_predictions(titanic_fit, type = "class")
titanic_test_pred
```

```{r}
titanic_test_pred %>% 
  select(survived, age, age_status, sex, pred)

```

```{r}
library(yardstick)
```


```{r}
titanic_test_pred %>% 
  conf_mat(truth = survived, estimate = pred)
```

1) People who survived and was predicted to be survived are 22 - TRUE POSITIVE

2) People who survived but was predicted that they wouldn't is 1 - FALSE POSITIVE

3) People who didn't survive and was predicted were also same are 4 - TRUE NEGATIVE

4) People who didn't survive and was predicted that they would survive are 9 - FALSE NEGATIVE

